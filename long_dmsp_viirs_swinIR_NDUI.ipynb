{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Single script for\n",
        "1. long dmsp train weight\n",
        "2. long dmsp_viirs_swinIR\n",
        "3. long NDUI"
      ],
      "metadata": {
        "id": "_y0wRBWd35Nw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#1. Mounting Google Drive"
      ],
      "metadata": {
        "id": "nTkKnd8D2fVE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vOrolQpX2iOH",
        "outputId": "675f4f25-2a98-4b07-9df2-c180adad3151"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DY5GUMjX2i9x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2. Calling all required libraries"
      ],
      "metadata": {
        "id": "tN-5XRBx20Wd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    import geopandas as gpd\n",
        "    import shapefile\n",
        "    from osgeo import ogr,osr,gdal\n",
        "except:\n",
        "    !pip install geopandas\n",
        "    !pip install PyShp\n",
        "    !pip install gdal\n",
        "import geopandas as gpd\n",
        "import shapefile\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import xarray as xr\n",
        "import os\n",
        "import time\n",
        "from osgeo import ogr,osr,gdal\n",
        "import tensorflow as tf\n",
        "import io\n",
        "import ee, folium\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "JJcDoqC424Rz"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "25VUCQiF3pMr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3. Authenticate and Initialize GEE Project"
      ],
      "metadata": {
        "id": "GpDYXhjv3prL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ee.Authenticate()\n",
        "ee.Initialize(project='ee-manmeet20singh15-wbis')"
      ],
      "metadata": {
        "id": "ViY4cosT3X6_"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install timm\n",
        "!pip install wxee\n",
        "import wxee\n",
        "wxee.Initialize()"
      ],
      "metadata": {
        "id": "Fk9-45xf3FKS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Bsw5RHUd3xcs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#4. Calling the SwinIR function\n",
        "The swinIR function for training weights and model load is written in another file 'SwinIR_train_function.py'"
      ],
      "metadata": {
        "id": "QEoMcxQJ4XR_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# runnig '.py' file\n",
        "%run drive/MyDrive/Shivam/Long_DMSP_NDUI/SwinIR_train_function.py"
      ],
      "metadata": {
        "id": "VMcVvc0W4jl5"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GYo_PFJD6p_w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#5. Loading ndui city file with Lat Lon"
      ],
      "metadata": {
        "id": "kTQa3k5l7tzX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_excel('drive/MyDrive/Shivam/Long_DMSP_NDUI/US_DOE_SW_IFL_cities.xlsx')\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "trJ7Ya0z709E",
        "outputId": "4bdb9842-fb3f-42cc-ac6f-3a4df66a20e8"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        Name      lat      lon\n",
              "0  Baltimore  39.2904 -76.6122\n",
              "1    Chicago  41.8781 -87.6298\n",
              "2  Beaumount  30.0802 -94.1266"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-82c67765-c0ff-415e-a612-e9caa0870b2f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Name</th>\n",
              "      <th>lat</th>\n",
              "      <th>lon</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Baltimore</td>\n",
              "      <td>39.2904</td>\n",
              "      <td>-76.6122</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Chicago</td>\n",
              "      <td>41.8781</td>\n",
              "      <td>-87.6298</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Beaumount</td>\n",
              "      <td>30.0802</td>\n",
              "      <td>-94.1266</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-82c67765-c0ff-415e-a612-e9caa0870b2f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-82c67765-c0ff-415e-a612-e9caa0870b2f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-82c67765-c0ff-415e-a612-e9caa0870b2f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-3ba981b3-da32-483d-8d17-6ba032062949\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3ba981b3-da32-483d-8d17-6ba032062949')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-3ba981b3-da32-483d-8d17-6ba032062949 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_bc0a7f71-8933-4f35-a54a-f25e122d41ba\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_bc0a7f71-8933-4f35-a54a-f25e122d41ba button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"Name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Baltimore\",\n          \"Chicago\",\n          \"Beaumount\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"lat\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 6.2010001846476355,\n        \"min\": 30.0802,\n        \"max\": 41.8781,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          39.2904,\n          41.8781,\n          30.0802\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"lon\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 8.853908057650774,\n        \"min\": -94.1266,\n        \"max\": -76.6122,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          -76.6122,\n          -87.6298,\n          -94.1266\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "city_names=[]\n",
        "for i in range(len(df.Name)):\n",
        "  city = str(df.Name[i])\n",
        "  city_names.append(city)\n",
        "city_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jeilv39N767g",
        "outputId": "3b20ddef-a472-4295-f2c3-a64a691fc35f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Baltimore', 'Chicago', 'Beaumount']"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lats_=[]\n",
        "for i in range(len(df.lat)):\n",
        "  lat_city = (df.lat[i])\n",
        "  lats_.append(lat_city)\n",
        "lats_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ql23r1Ww8UB2",
        "outputId": "3ac1c77c-d35f-4eae-c132-80d143055cf2"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[39.2904, 41.8781, 30.0802]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lons_=[]\n",
        "for i in range(len(df.lon)):\n",
        "  lon_city = (df.lon[i])\n",
        "  lons_.append(lon_city)\n",
        "lons_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eKrK2VZ68YQR",
        "outputId": "94c42048-b358-400b-c899-aa623ec8ba66"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[-76.6122, -87.6298, -94.1266]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-Ttxqovm8aX3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#6. Creating city directory for the cities in the list"
      ],
      "metadata": {
        "id": "qck4p-2U8o03"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cities_folder = 'drive/MyDrive/Shivam/Long_DMSP_NDUI/Test_City/'\n",
        "os.mkdir(cities_folder)\n",
        "\n",
        "for city in city_names:\n",
        "  city_folder = os.path.join(cities_folder, city)\n",
        "  os.mkdir(city_folder)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "ZfNsNqhz8sW6",
        "outputId": "c4bb0f36-9734-48c1-a77d-839cee236529"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileExistsError",
          "evalue": "[Errno 17] File exists: 'drive/MyDrive/Shivam/Long_DMSP_NDUI/Test_City/'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-71775bbb0d68>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcities_folder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'drive/MyDrive/Shivam/Long_DMSP_NDUI/Test_City/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcities_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcity\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcity_names\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mcity_folder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcities_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcity\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileExistsError\u001b[0m: [Errno 17] File exists: 'drive/MyDrive/Shivam/Long_DMSP_NDUI/Test_City/'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cities_folder"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "Tk0DyF4y9Oeu",
        "outputId": "e0e26cf5-ee5f-41c2-e7b9-2ad04315d87e"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'drive/MyDrive/Shivam/Long_DMSP_NDUI/Test_City/'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#7. Calling SwinIR model, DMSP images from GEE and correction coefficient"
      ],
      "metadata": {
        "id": "wdmPnHsoA8aQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "upscale = 1\n",
        "window_size = 5\n",
        "height = 30 #(1024 // upscale // window_size + 1) * window_size\n",
        "width = 30 #(720 // upscale // window_size + 1) * window_size\n",
        "device = 'cuda'\n",
        "model = SwinIR(upscale=1, img_size=(height, width),\n",
        "               window_size=window_size, img_range=1., depths=[6, 6, 6, 6],\n",
        "               embed_dim=60, num_heads=[6, 6, 6, 6], mlp_ratio=2, upsampler='pixelshuffledirect').to(device)\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "F101992 = ee.Image('NOAA/DMSP-OLS/NIGHTTIME_LIGHTS/F101992').select('stable_lights')\n",
        "F101993 = ee.Image('NOAA/DMSP-OLS/NIGHTTIME_LIGHTS/F101993').select('stable_lights')\n",
        "F101994 = ee.Image('NOAA/DMSP-OLS/NIGHTTIME_LIGHTS/F101994').select('stable_lights')\n",
        "F121994 = ee.Image('NOAA/DMSP-OLS/NIGHTTIME_LIGHTS/F121994').select('stable_lights')\n",
        "F121995 = ee.Image('NOAA/DMSP-OLS/NIGHTTIME_LIGHTS/F121995').select('stable_lights')\n",
        "F121996 = ee.Image('NOAA/DMSP-OLS/NIGHTTIME_LIGHTS/F121996').select('stable_lights')\n",
        "F121997 = ee.Image('NOAA/DMSP-OLS/NIGHTTIME_LIGHTS/F121997').select('stable_lights')\n",
        "F121998 = ee.Image('NOAA/DMSP-OLS/NIGHTTIME_LIGHTS/F121998').select('stable_lights')\n",
        "F121999 = ee.Image('NOAA/DMSP-OLS/NIGHTTIME_LIGHTS/F121999').select('stable_lights')\n",
        "F141997 = ee.Image('NOAA/DMSP-OLS/NIGHTTIME_LIGHTS/F141997').select('stable_lights')\n",
        "F141998 = ee.Image('NOAA/DMSP-OLS/NIGHTTIME_LIGHTS/F141998').select('stable_lights')\n",
        "F141999 = ee.Image('NOAA/DMSP-OLS/NIGHTTIME_LIGHTS/F141999').select('stable_lights')\n",
        "F142000 = ee.Image('NOAA/DMSP-OLS/NIGHTTIME_LIGHTS/F142000').select('stable_lights')\n",
        "F142001 = ee.Image('NOAA/DMSP-OLS/NIGHTTIME_LIGHTS/F142001').select('stable_lights')\n",
        "F142002 = ee.Image('NOAA/DMSP-OLS/NIGHTTIME_LIGHTS/F142002').select('stable_lights')\n",
        "F142003 = ee.Image('NOAA/DMSP-OLS/NIGHTTIME_LIGHTS/F142003').select('stable_lights')\n",
        "F152000 = ee.Image('NOAA/DMSP-OLS/NIGHTTIME_LIGHTS/F152000').select('stable_lights')\n",
        "F152001 = ee.Image('NOAA/DMSP-OLS/NIGHTTIME_LIGHTS/F152001').select('stable_lights')\n",
        "F152002 = ee.Image('NOAA/DMSP-OLS/NIGHTTIME_LIGHTS/F152002').select('stable_lights')\n",
        "F152003 = ee.Image('NOAA/DMSP-OLS/NIGHTTIME_LIGHTS/F152003').select('stable_lights')\n",
        "F152004 = ee.Image('NOAA/DMSP-OLS/NIGHTTIME_LIGHTS/F152004').select('stable_lights')\n",
        "F152005 = ee.Image('NOAA/DMSP-OLS/NIGHTTIME_LIGHTS/F152005').select('stable_lights')\n",
        "F152006 = ee.Image('NOAA/DMSP-OLS/NIGHTTIME_LIGHTS/F152006').select('stable_lights')\n",
        "F152007 = ee.Image('NOAA/DMSP-OLS/NIGHTTIME_LIGHTS/F152007').select('stable_lights')\n",
        "F162004 = ee.Image('NOAA/DMSP-OLS/NIGHTTIME_LIGHTS/F162004').select('stable_lights')\n",
        "F162005 = ee.Image('NOAA/DMSP-OLS/NIGHTTIME_LIGHTS/F162005').select('stable_lights')\n",
        "F162006 = ee.Image('NOAA/DMSP-OLS/NIGHTTIME_LIGHTS/F162006').select('stable_lights')\n",
        "F162007 = ee.Image('NOAA/DMSP-OLS/NIGHTTIME_LIGHTS/F162007').select('stable_lights')\n",
        "F162008 = ee.Image('NOAA/DMSP-OLS/NIGHTTIME_LIGHTS/F162008').select('stable_lights')\n",
        "F162009 = ee.Image('NOAA/DMSP-OLS/NIGHTTIME_LIGHTS/F162009').select('stable_lights')\n",
        "F182010 = ee.Image('NOAA/DMSP-OLS/NIGHTTIME_LIGHTS/F182010').select('stable_lights')\n",
        "F182011 = ee.Image('NOAA/DMSP-OLS/NIGHTTIME_LIGHTS/F182011').select('stable_lights')\n",
        "F182012 = ee.Image('NOAA/DMSP-OLS/NIGHTTIME_LIGHTS/F182012').select('stable_lights')\n",
        "\n",
        "collections = [F101992, F101993, F101994, F121994, F121995, F121996, F121997, F121998, F121999, F141997, F141998,\n",
        "                    F141999, F142000, F142001,F142002, F142003, F152000, F152001, F152002, F152003, F152004, F152005,\n",
        "                    F152006, F152007,F162004, F162005, F162006, F162007, F162008, F162009, F182010, F182011, F182012]\n",
        "\n",
        "c = [-3.06516, -2.0638, -1.68421, -1.71621, 0.530922, 0.303469, -0.18513, 0.490138, 1.800988, -0.6186,\n",
        "         -0.91352, -1.37993, 0.061872, 0.249452, 1.127103, 0.866522,0, 0.005164,-0.04462, -0.27189, -0.06977, 0.449229,\n",
        "         0.913485, 0.644785, -0.02563, -0.54115, -0.38377, 0.629564, 0.745403, -0.15161, 6.22332, 1.427157, 3.866698]\n",
        "\n",
        "b = [-0.00698, -0.00726, -0.00695, -0.00454, 0.00011, -0.00176, -0.00057, 0.001236, 0.002969, -0.0094,\n",
        "     -0.00929, -0.00889, -0.00469, -0.00452, -0.00221, -0.00351, 0, 8.94e-05, 0.000117, -0.0085, -0.00912, -0.00601,\n",
        "     -0.00595, -0.00675, -0.00496, -0.0094, -0.0061, -0.00084, -0.00062, -0.00278, 0.014627,0.002877, 0.007962]\n",
        "\n",
        "a = [1.519907, 1.516595, 1.491333, 1.331971, 0.984465, 1.111207, 1.034429, 0.905787, 0.761106, 1.603921,\n",
        "      1.603648, 1.586457, 1.294471, 1.275902, 1.128708, 1.206319, 1, 1.002879, 0.987943, 1.555808, 1.591033, 1.401146,\n",
        "      1.381139,1.448976, 1.317581, 1.613536, 1.41435, 1.040815, 1.037042, 1.193437, -0.08536, 0.774923, 0.355542]"
      ],
      "metadata": {
        "id": "x_r-XWKeBA0w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Image correction using coefficient\n",
        "images = [0 for _ in range(33)]\n",
        "count = 0\n",
        "total_list = []\n",
        "images_correct = [0 for _ in range(33)]\n",
        "\n",
        "def fun3(raw,correct):\n",
        "    out = correct.where(raw.lt(5.0),raw.float())\n",
        "    return out\n",
        "\n",
        "for i in range(33):\n",
        "    images[i] = ee.Image(a[i]).multiply(collections[i].float()).add(ee.Image(b[i]).multiply(collections[i].float().pow(2))).add(ee.Image(c[i]))\n",
        "    images_correct[i] = fun3(collections[i],images[i]).select('constant')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "jZccYiWCBwaa",
        "outputId": "9a7e1d4d-ac88-4631-f477-a5af73ce516a"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'a' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-a9b3a5eb74bc>\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m33\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mee\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcollections\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mee\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcollections\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mee\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mimages_correct\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfun3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcollections\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'constant'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'a' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lZgQfUEiJFf3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#8. Unpatchify"
      ],
      "metadata": {
        "id": "4pKunnqvJLfd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def unpatchify(patches, img_shape):\n",
        "    patch_size = patches.shape[1]\n",
        "    assert patches.shape[0] == (img_shape[0] // patch_size) * (img_shape[1] // patch_size), \"Patches and image shape are not compatible\"\n",
        "\n",
        "    img = np.zeros(img_shape, dtype=patches.dtype)\n",
        "    patch_idx = 0\n",
        "\n",
        "    for i in range(0, img_shape[0], patch_size):\n",
        "        for j in range(0, img_shape[1], patch_size):\n",
        "            img[i:i + patch_size, j:j + patch_size] = patches[patch_idx]\n",
        "            patch_idx += 1\n",
        "\n",
        "    return img\n",
        "\n",
        "def patchify(img, patch_size):\n",
        "    img_shape = img.shape\n",
        "    patches = np.array([img[i:i + patch_size, j:j + patch_size] for i in range(0, img_shape[0], patch_size) for j in range(0, img_shape[1], patch_size)])\n",
        "    return patches\n",
        "\n",
        "class ncDataset(Dataset):\n",
        "    def __init__(self, data, targets):\n",
        "        self.data = data\n",
        "        self.targets = targets\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        x = torch.from_numpy(self.data[index]).unsqueeze(0)\n",
        "        y = torch.from_numpy(self.targets[index]).unsqueeze(0)\n",
        "        # x = self.data[index]\n",
        "        # y = self.targets[index]\n",
        "        # x = x.to(dtype=torch.float32)\n",
        "        # y = y.to(dtype=torch.float32)\n",
        "        return x, y\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)"
      ],
      "metadata": {
        "id": "7ieLysblJQ5X"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Nl9dlFDmJS5U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#9. Training and saving the weights '.pth' into city directory"
      ],
      "metadata": {
        "id": "4hM47zvHJgsG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Lon: 98-113E\n",
        "#Lat: 20-35N\n",
        "\n",
        "# import os\n",
        "# directory = 'drive/MyDrive/Shivam/Long_DMSP_NDUI/Test/'\n",
        "# cities = ['la', 'albuquerque', 'denver', 'portland', 'louisville', 'washington_dc', 'kansas_city', 'columbus', 'minneapolis', 'seattle']\n",
        "# lats_  = [34.0549, 35.0844, 39.7392, 45.5152, 38.2527, 38.9072, 39.0997, 39.9612, 44.9778, 47.6062]\n",
        "# lons_  = [-118.2426, -106.6504, -104.9903, -122.6784, -85.7585, -77.0369, -94.5786, -82.9988, -93.2650, -122.3321]\n",
        "\n",
        "buffer = 2.5\n",
        "\n",
        "for i_city, city in enumerate(city_names):\n",
        "    if not os.path.exists(cities_folder+city_names[i_city]\"/best_model_\"+city_names[i_city]+\".pth\"):\n",
        "\n",
        "        lats, late = lats_[i_city]-buffer, lats_[i_city]+buffer\n",
        "        lons, lone = lons_[i_city]-buffer, lons_[i_city]+buffer\n",
        "\n",
        "        aoi = ee.Geometry.Polygon(\n",
        "                [[[lons, lats],\n",
        "                [lone, lats],\n",
        "                [lone, late],\n",
        "                [lons, late]]])\n",
        "        coords = aoi.coordinates().getInfo()[0]\n",
        "\n",
        "        # Calling VIIRS data from GEE\n",
        "\n",
        "        dataset = ee.ImageCollection('NOAA/VIIRS/DNB/MONTHLY_V1/VCMCFG').filter(ee.Filter.date('2012-01-01', '2013-12-31'))\n",
        "        viirs_image_2012 = dataset#.select('avg_rad').mean()\n",
        "        viirs_image_2012 = viirs_image_2012.set('system:time_start', 0)\n",
        "        ds_viirs = viirs_image_2012.wx.to_xarray(region=aoi.bounds(), scale=463.83)\n",
        "\n",
        "        dmsp_image_2012 = images_correct[-1]\n",
        "        dmsp_image_2012 = dmsp_image_2012.set('system:time_start', 0)\n",
        "        ds_dmsp = dmsp_image_2012.wx.to_xarray(region=aoi.bounds(), scale=927.67)\n",
        "\n",
        "        ds_viirs_ = ds_viirs.sel(time=slice('2012','2012')).mean(dim='time').interp(x=ds_dmsp.x.values, y=ds_dmsp.y.values,method=\"cubic\", kwargs={\"fill_value\": \"extrapolate\"})\n",
        "\n",
        "        x_train = ds_viirs_.avg_rad.values.astype(np.float32)\n",
        "        y_train = ds_dmsp.constant.values[0,:,:].astype(np.float32)\n",
        "\n",
        "        # Create patches from the image\n",
        "        patch_size = 30\n",
        "        img = x_train[:600,:600]\n",
        "        patches = patchify(img, patch_size)\n",
        "\n",
        "        x_train_max = x_train.max()\n",
        "        y_train_max = y_train.max()\n",
        "        x_train /= x_train_max\n",
        "        y_train /= y_train_max\n",
        "\n",
        "        x_train_patches = patchify(x_train[:600,:600], patch_size)\n",
        "        y_train_patches = patchify(y_train[:600,:600], patch_size)\n",
        "\n",
        "        x_val_patches = x_train_patches[200:300]\n",
        "        y_val_patches = y_train_patches[200:300]\n",
        "\n",
        "        x_test_patches = x_train_patches[300:400]\n",
        "        y_test_patches = y_train_patches[300:400]\n",
        "\n",
        "        x_train_patches = x_train_patches[:200]\n",
        "        y_train_patches = y_train_patches[:200]\n",
        "\n",
        "        train_dataset = ncDataset(x_train_patches, y_train_patches)\n",
        "        val_dataset = ncDataset(x_val_patches, y_val_patches)\n",
        "        test_dataset = ncDataset(x_val_patches, y_val_patches)\n",
        "\n",
        "        train_dataloader = DataLoader(train_dataset, batch_size=20, shuffle=True)\n",
        "        val_dataloader = DataLoader(val_dataset, batch_size=20, shuffle=True)\n",
        "        test_dataloader = DataLoader(test_dataset, batch_size=20, shuffle=True)\n",
        "\n",
        "        from copy import deepcopy\n",
        "\n",
        "        num_epochs = 1000\n",
        "        print_interval = 100\n",
        "        patience = 500\n",
        "        best_val_loss = float('inf')\n",
        "        counter = 0\n",
        "        best_model = None\n",
        "\n",
        "        writer = SummaryWriter(\"runs/swinir\")\n",
        "        for epoch in range(1, num_epochs + 1):\n",
        "            train_loss, val_loss = train(model, train_dataloader, val_dataloader, criterion, optimizer, device)\n",
        "        # Log losses to TensorBoard\n",
        "            writer.add_scalars(\"Loss\", {\"Train\": train_loss, \"Validation\": val_loss}, epoch)\n",
        "\n",
        "            if val_loss < best_val_loss:\n",
        "                best_val_loss = val_loss\n",
        "                best_model = deepcopy(model)\n",
        "                counter = 0\n",
        "            else:\n",
        "                counter += 1\n",
        "\n",
        "            if epoch % print_interval == 0:\n",
        "                print(f\"Epoch [{epoch}/{num_epochs}] - Train Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f}\")\n",
        "\n",
        "            if counter >= patience:\n",
        "                print(\"Early stopping triggered.\")\n",
        "                break\n",
        "        writer.close()\n",
        "\n",
        "        model_save_path = city_names[i_city]+\"/best_model_\"+city_names[i_city]+\".pth\"\n",
        "        torch.save(best_model.state_dict(), cities_folder+model_save_path)"
      ],
      "metadata": {
        "id": "7JMy7lVPJnv0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Qthkpwf7MHCx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#10. Calling best model city weights and load the model"
      ],
      "metadata": {
        "id": "QWK9zwHQOW51"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_model_swinir_path =[]\n",
        "for i in range(len(city_names)):\n",
        "  path = cities_folder+city_names[i]+'/best_model_'+str(city_names[i])+'.pth'\n",
        "  best_model_swinir_path.append(path)\n",
        "best_model_swinir_path"
      ],
      "metadata": {
        "id": "W4SDh47mMHFO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_model_city= []\n",
        "for i in range(len(city_names)):\n",
        "  model_save_path = best_model_swinir_path[i]\n",
        "  upscale = 1\n",
        "  window_size = 5\n",
        "  height = 30 #(1024 // upscale // window_size + 1) * window_size\n",
        "  width = 30 #(720 // upscale // window_size + 1) * window_size\n",
        "  device = 'cuda'\n",
        "  loaded_model = SwinIR(upscale=1, img_size=(height, width),\n",
        "               window_size=window_size, img_range=1., depths=[6, 6, 6, 6],\n",
        "               embed_dim=60, num_heads=[6, 6, 6, 6], mlp_ratio=2, upsampler='pixelshuffledirect').to(device)\n",
        "  loaded_model.load_state_dict(torch.load(model_save_path))\n",
        "  loaded_model.eval()\n",
        "  loaded_model_city.append(loaded_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "WVfBNLihMHIp",
        "outputId": "6d8fb7d6-d97f-4c80-f26e-963b14bf16f7"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Baltimore'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "utuHUpjkOoGy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#11. defining Area of interest"
      ],
      "metadata": {
        "id": "pJ_LdKLOPJuv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "aoi_city = []\n",
        "for i in range(len(df.lat)):\n",
        "  lats, late = df.lat[i]-2.5, df.lat[i]+2.5\n",
        "  lons, lone = df.lon[i]-2.5, df.lon[i]+2.5\n",
        "  aoi = ee.Geometry.Polygon(\n",
        "        [[[lons, lats],\n",
        "          [lone, lats],\n",
        "          [lone, late],\n",
        "          [lons, late]]])\n",
        "  aoi_city.append(aoi)\n",
        "aoi_city[0]"
      ],
      "metadata": {
        "id": "yH0zFjRLPJ7w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "coords = aoi_city[0].coordinates().getInfo()[0]\n",
        "coords"
      ],
      "metadata": {
        "id": "5sUncrjHPJ_S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#12. DMSP 2012 for City in the List"
      ],
      "metadata": {
        "id": "XD_Ho9gaPZfg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dmsp_image_2012 = images_correct[-1]\n",
        "years = np.arange(2012,1991,-1)\n",
        "#years\n",
        "indices = [-1, -2, -3, -4, -5, -6, -7, -8, -9, -14, -15, -16, -17, -22, -23, -24, -28, -29, -30, -32, -33]\n",
        "dmsp_image = images_correct[indices[0]]\n",
        "years[indices[0]]"
      ],
      "metadata": {
        "id": "eXiDPcX7Pb_1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dmsp_image_2012 = dmsp_image_2012.set('system:time_start', 0)\n",
        "ds_dmsp_2012_city = []\n",
        "for i in range(len(city_names)):\n",
        "  ds_dmsp_c2012 = dmsp_image_2012.wx.to_xarray(region=aoi_city[i].bounds(), scale=927.67)\n",
        "  ds_dmsp_2012_city.append(ds_dmsp_c2012)\n",
        "ds_dmsp_2012_city[0]"
      ],
      "metadata": {
        "id": "FiVYR03vefCT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "N0Ccnhi0egTt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#13. VIIRS 2012 for Cities in the list\n",
        "## Why we have taken VIIRS from 01-01-2012 to 31-12-2013??"
      ],
      "metadata": {
        "id": "jnt6lJCBet7C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calling VIIRS 2012 from GEE\n",
        "dataset = ee.ImageCollection('NOAA/VIIRS/DNB/MONTHLY_V1/VCMCFG').filter(ee.Filter.date('2012-01-01', '2013-12-31'))\n",
        "viirs_image_2012 = dataset#.select('avg_rad').mean()"
      ],
      "metadata": {
        "id": "y_pSJy1UegXC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## clipping for cities in the list\n",
        "viirs_image_2012 = viirs_image_2012.set('system:time_start', 0)\n",
        "ds_viirs_2012_city=[]\n",
        "for i in range(len(city_names)):\n",
        "  ds_viirs_c2012 = viirs_image_2012.wx.to_xarray(region=aoi_city[i].bounds(), scale=463.83)\n",
        "  ds_viirs_2012_city.append(ds_viirs_c2012)\n",
        "ds_viirs_2012_city[0]"
      ],
      "metadata": {
        "id": "9gM4zDFDfXfJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2hpAOPRifXik"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#14. Interpolating VIIRS city lat lon to DMSP City Lat Lon"
      ],
      "metadata": {
        "id": "EJcJgbaffnV8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ds_viirs_i2012_city = []\n",
        "for i in range(len(city_names)):\n",
        "  ds_viirs_ic2012= ds_viirs_2012_city[i].sel(time=slice('2012','2012')).mean(dim='time').interp(x=ds_dmsp_2012_city[i].x.values, y=ds_dmsp_2012_city[i].y.values,method=\"cubic\", kwargs={\"fill_value\": \"extrapolate\"})\n",
        "  ds_viirs_i2012_city.append(ds_viirs_ic2012)\n",
        "ds_viirs_i2012_city[0]"
      ],
      "metadata": {
        "id": "16xDF6CCfs85"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Nmh6fIxEf1AJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#15. Creating training dataset for cities from interp-VIIRS and DMSP"
      ],
      "metadata": {
        "id": "yynz4nZrf86W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_2012_city =[]\n",
        "y_train_2012_city = []\n",
        "for i in range(len(city_names)):\n",
        "  x_train_2012 = ds_viirs_i2012_city[i].avg_rad.values.astype(np.float32)\n",
        "  y_train_2012 = ds_dmsp_2012_city[i].constant.values[0,:,:].astype(np.float32)\n",
        "  x_train_2012_city.append(x_train_2012)\n",
        "  y_train_2012_city.append(y_train_2012)\n",
        "x_train_2012_city[0], y_train_2012_city[0]"
      ],
      "metadata": {
        "id": "_o16t7XSf1j2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mcxjZa_OgHjC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Getting max value of training dataset for City\n",
        "x_train_2012_max_city = []\n",
        "y_train_2012_max_city = []\n",
        "for i in range(len(city_names)):\n",
        "  x_train_c2012_m = x_train_2012_city[i].max()\n",
        "  y_train_c2012_m = y_train_2012_city[i].max()\n",
        "  x_train_2012_max_city.append(x_train_c2012_m)\n",
        "  y_train_2012_max_city.append(y_train_c2012_m)"
      ],
      "metadata": {
        "id": "459ytyJcgHma"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zddmCovFhVGN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Unpatchify and Patchify defined earlier at Point 8"
      ],
      "metadata": {
        "id": "yETEshXPhxK1"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ceR-ZeSZhWaW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#16. Create patches from the images for cities"
      ],
      "metadata": {
        "id": "o99FFQb2iBqk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "patch_size = 30\n",
        "\n",
        "patches_2012_city =[]\n",
        "img_2012_city = []\n",
        "for i in range(len(city_names)):\n",
        "  img_c2012 = x_train_2012_city[i][:600,:600]\n",
        "  patches_c2012 = patchify(img_c2012, patch_size)\n",
        "  img_2012_city.append(img_c2012)\n",
        "  patches_2012_city.append(patches_c2012)"
      ],
      "metadata": {
        "id": "HL7N3sXWhWdy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#17. loading swinIR model for patchified training dataset and unpatchifying for reconstructed predicted 2012 dataset for cities in List"
      ],
      "metadata": {
        "id": "UGkjlEZCiagh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reconstructed_predicted_sr_2012_city =[]\n",
        "\n",
        "for i in range(len(city_names)):\n",
        "  x_train_c2012 = x_train_2012_city[i]\n",
        "  y_train_c2012 = y_train_2012_city[i]\n",
        "  x_train_c2012_max = x_train_c2012.max()\n",
        "  y_train_c2012_max = y_train_c2012.max()\n",
        "  # Normalizing\n",
        "  x_train_c2012 /= x_train_c2012_max       #sets x_train to x_train/x_train_max\n",
        "  y_train_c2012 /= y_train_c2012_max\n",
        "  x_train_patches_c2012 = patchify(x_train_c2012[:600,:600], patch_size)[:,np.newaxis,:,:]\n",
        "  x_train_patches_c2012_tensor = torch.from_numpy(x_train_patches_c2012).to(device)\n",
        "  with torch.no_grad():\n",
        "    predicted_sr_c2012 = loaded_model_city[i](x_train_patches_c2012_tensor)\n",
        "  predicted_sr_c2012_np = predicted_sr_c2012.cpu().numpy() * y_train_c2012_max  #why .cpu() used??\n",
        "  predicted_sr_c2012_np[predicted_sr_c2012_np<0] = 0.0\n",
        "  reconstructed_predicted_sr_c2012 = unpatchify(predicted_sr_c2012_np[:,0,:,:], img_2012_city[i].shape)\n",
        "  reconstructed_predicted_sr_2012_city.append(reconstructed_predicted_sr_c2012)"
      ],
      "metadata": {
        "id": "dR0pJvxNia19"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#18. DMSP like VIIRS using SwinIR for Cities in the List for year 2012"
      ],
      "metadata": {
        "id": "Wz8uk7hIjztI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ds_dmsp_vi_swin_2012_city = []\n",
        "for i in range(len(city_names)):\n",
        "  lats_c2012 = ds_dmsp_2012_city[i].y.values[:600]\n",
        "  lons_c2012 =  ds_dmsp_2012_city[i].x.values[:600]\n",
        "  dmsp_c2012_ = ds_dmsp_2012_city[i].constant.values[0,:600,:600]\n",
        "  ds_dmsp_vi_swin_c2012 = xr.Dataset({\n",
        "    'dmsp': xr.DataArray(\n",
        "                data   = dmsp_c2012_,   # enter data here\n",
        "                dims   = ['lat', 'lon'],\n",
        "                coords = {'lat': lats_c2012, 'lon': lons_c2012},\n",
        "\n",
        "                ),\n",
        "    'viirs_swinir': xr.DataArray(\n",
        "                data   = reconstructed_predicted_sr_2012_city[i],   # enter data here\n",
        "                dims   = ['lat', 'lon'],\n",
        "                coords = {'lat': lats_c2012, 'lon': lons_c2012},\n",
        "                ),\n",
        "    'viirs': xr.DataArray(\n",
        "                data   = ds_viirs_i2012_city[i].avg_rad.values[:600,:600],   # enter data here\n",
        "                dims   = ['lat', 'lon'],\n",
        "                coords = {'lat': lats_c2012, 'lon': lons_c2012},\n",
        "                )\n",
        "            },\n",
        "    )\n",
        "  ds_dmsp_vi_swin_2012_city.append(ds_dmsp_vi_swin_c2012)\n",
        "\n",
        "ds_dmsp_vi_swin_2012_city[0]"
      ],
      "metadata": {
        "id": "La4jZrtUia5h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#19. DMSP dataset for Listed Cities from 1992-2012"
      ],
      "metadata": {
        "id": "MK7bUkLLkdRr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# setting date for annual data\n",
        "dates = pd.date_range('1992', '2012', freq='YS')[::-1]\n",
        "dates"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EOSC3sZCklTo",
        "outputId": "2fd846a9-521e-46a6-bfdf-7d4e9401cbaa"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatetimeIndex(['2012-01-01', '2011-01-01', '2010-01-01', '2009-01-01',\n",
              "               '2008-01-01', '2007-01-01', '2006-01-01', '2005-01-01',\n",
              "               '2004-01-01', '2003-01-01', '2002-01-01', '2001-01-01',\n",
              "               '2000-01-01', '1999-01-01', '1998-01-01', '1997-01-01',\n",
              "               '1996-01-01', '1995-01-01', '1994-01-01', '1993-01-01',\n",
              "               '1992-01-01'],\n",
              "              dtype='datetime64[ns]', freq='-1AS-JAN')"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating dmsp timeseries dataset for Cities\n",
        "ds_dmsp_2012_1992_city = []\n",
        "for j in range(len(city_names)):\n",
        "  dmsp_c2012_1992 = []\n",
        "  for i_ind,ind in enumerate(indices):\n",
        "    dmsp_image = images_correct[ind]\n",
        "    print(years[i_ind])\n",
        "    dmsp_image = dmsp_image.set('system:time_start', 0)\n",
        "    ds_dmsp_c = dmsp_image.wx.to_xarray(region=aoi_city[j].bounds(), scale=927.67)\n",
        "    dmsp_c2012_1992.append(ds_dmsp_c.constant.values[0,:600,:600])\n",
        "  dmsp_c2012_1992_np =  np.stack(dmsp_c2012_1992)\n",
        "  print(dmsp_c2012_1992_np.shape)\n",
        "  print(ds_dmsp_c.x[0])\n",
        "\n",
        "  lats_c = ds_dmsp_c.y.values[:600]\n",
        "  lons_c = ds_dmsp_c.x.values[:600]\n",
        "\n",
        "  ds_dmsp_c2012_1992 = xr.Dataset({\n",
        "        'dmsp': xr.DataArray(\n",
        "                    data   = dmsp_c2012_1992_np,   # enter data here\n",
        "                    dims   = ['time', 'lat', 'lon'],\n",
        "                    coords = {'time':dates, 'lat': lats_c, 'lon': lons_c},\n",
        "\n",
        "                    ),\n",
        "               },\n",
        "         )\n",
        "  ds_dmsp_2012_1992_city.append(ds_dmsp_c2012_1992)\n",
        "  print(ds_dmsp_c.constant.values.mean())\n",
        "\n",
        "ds_dmsp_2012_1992_city[0]"
      ],
      "metadata": {
        "id": "fE3oABmZkq_E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(city_names)):\n",
        "  ds_dmsp_2012_1992_city[i].to_netcdf(cities_folder+city_names[i]+'/dmsp_1992_2012_'+city_names[i]+'.nc')\n",
        "# !ls drive/MyDrive/Shivam/Long_DMSP_NDUI/Cities/Baltimore"
      ],
      "metadata": {
        "id": "d3CpyFuWldw2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xkOSljGEnY2S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#20. Generating DMSP like VIIRS dataset for Listed Cities from 2013-2022"
      ],
      "metadata": {
        "id": "uqXiAP8por4m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dates = pd.date_range('2013', '2022', freq='YS')\n",
        "dates"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cT1dkfZFo5cx",
        "outputId": "77cfa4ab-ccfd-48e3-95e3-553d86ec296c"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatetimeIndex(['2013-01-01', '2014-01-01', '2015-01-01', '2016-01-01',\n",
              "               '2017-01-01', '2018-01-01', '2019-01-01', '2020-01-01',\n",
              "               '2021-01-01', '2022-01-01'],\n",
              "              dtype='datetime64[ns]', freq='AS-JAN')"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dates.year"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qWxo59ITsJr7",
        "outputId": "f050cc1d-e2bd-44a8-a3fb-ee66fe8e4fbb"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index([2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022], dtype='int32')"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dates.year[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "htq8LADhsXhy",
        "outputId": "033c530a-795b-40ce-86cb-985152b30dd6"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2013"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ds_dmsp_2013_2022_city = []\n",
        "for j in range(len(city_names)):\n",
        "  print(city_names[j])\n",
        "  ds_dmsp_c2013_2022 = []\n",
        "  for year_ in range(2013,2023):\n",
        "    year = str(year_)#'2013'\n",
        "    dataset_y = ee.ImageCollection('NOAA/VIIRS/DNB/MONTHLY_V1/VCMCFG').filter(ee.Filter.date(year+'-01-01', year+'-12-31'))\n",
        "    viirs_image_y = dataset_y#.select('avg_rad').mean()\n",
        "    viirs_image_y = viirs_image_y.set('system:time_start', 0)\n",
        "    ds_viirs_c_y = viirs_image_y.wx.to_xarray(region=aoi_city[j].bounds(), scale=463.83)\n",
        "    ds_viirs_interp_c_y = ds_viirs_c_y.sel(time=slice(year,year)).mean(dim='time').interp(x=ds_dmsp_2012_city[j].x.values, y=ds_dmsp_2012_city[j].y.values,method=\"cubic\", kwargs={\"fill_value\": \"extrapolate\"})\n",
        "\n",
        "    x_train_c_y = ds_viirs_interp_c_y.avg_rad.values.astype(np.float32)\n",
        "    img_c_y = x_train_c_y[:600,:600]\n",
        "\n",
        "    print('x_train_2012_cj_max:',x_train_2012_max_city[j],'y_train_2012_cj_max:', y_train_2012_max_city[j])\n",
        "\n",
        "    x_train_c_y /= x_train_2012_max_city[j]\n",
        "    x_train_c_y_patches = patchify(x_train_c_y[:600,:600], patch_size)[:,np.newaxis,:,:]\n",
        "    x_train_c_y_patches_tensor = torch.from_numpy(x_train_c_y_patches).to(device)\n",
        "    with torch.no_grad():\n",
        "      predicted_sr_c_y = loaded_model_city[j](x_train_c_y_patches_tensor)\n",
        "    predicted_sr_c_y_np = predicted_sr_c_y.cpu().numpy() * y_train_2012_max_city[j]\n",
        "    predicted_sr_c_y_np[predicted_sr_c_y_np<0] = 0.0\n",
        "    reconstructed_predicted_sr_c_y = unpatchify(predicted_sr_c_y_np[:,0,:,:], img_c_y.shape)\n",
        "    ds_dmsp_c2013_2022.append(reconstructed_predicted_sr_c_y)\n",
        "\n",
        "  ds_dmsp_c2013_2022_np =  np.stack(ds_dmsp_c2013_2022)\n",
        "  print(ds_dmsp_c2013_2022_np.shape)\n",
        "\n",
        "  lats_cj = ds_dmsp_2012_city[j].y.values[:600]\n",
        "  lons_cj = ds_dmsp_2012_city[j].x.values[:600]\n",
        "  print(lats_cj[0], lats_cj[0])\n",
        "\n",
        "  ds_dmsp_cj_2013_2022 = xr.Dataset({\n",
        "    'dmsp': xr.DataArray(\n",
        "                data   = ds_dmsp_c2013_2022_np,   # enter data here\n",
        "                dims   = ['time', 'lat', 'lon'],\n",
        "                coords = {'time':dates, 'lat': lats_cj, 'lon': lons_cj},\n",
        "\n",
        "                ),\n",
        "            },\n",
        "    )\n",
        "  ds_dmsp_2013_2022_city.append(ds_dmsp_cj_2013_2022)\n",
        "#   print(ds_dmsp_cj_2013_2022.dmsp.mean())\n",
        "\n"
      ],
      "metadata": {
        "id": "SbokCBVlsNJL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(city_names)):\n",
        "  ds_dmsp_2013_2022_city[i].to_netcdf(cities_folder+city_names[i]+'/dmsp_2013_2022_'+str(city_names[i])+'.nc')\n",
        "# !ls drive/MyDrive/Shivam/Long_DMSP_NDUI/Cities/Baltimore"
      ],
      "metadata": {
        "id": "sxJjx0BXsw-D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#21. Long DMSP-VIIRS SwinIR 1992-2022"
      ],
      "metadata": {
        "id": "3alVWQwNuGUQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ds_dmsp_1992_2022_city = []\n",
        "for i in range(len(city_names)):\n",
        "  ds_dmsp_c_1992_2022 = xr.concat([ds_dmsp_2012_1992_city[i], ds_dmsp_2013_2022_city[i]], dim='time').sortby('time')\n",
        "  ds_dmsp_1992_2022_city.append(ds_dmsp_c_1992_2022)\n",
        "\n",
        "ds_dmsp_1992_2022_city[0]"
      ],
      "metadata": {
        "id": "FZl8VN9etK-Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(city_names)):\n",
        "  ds_dmsp_1992_2022_city[i].to_netcdf(cities_folder+city_names[i]+'/dmsp_swinIR_1992_2022_'+str(city_names[i])+'.nc')\n",
        "# !ls drive/MyDrive/Shivam/Long_DMSP_NDUI/Cities/Baltimore"
      ],
      "metadata": {
        "id": "bIgWaJ2SvG0p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#22. Long-NDUI\n",
        "ds_dmsp_1992_2022_city[i] will be used"
      ],
      "metadata": {
        "id": "e-IvmPnJvrBe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Area of Interest\n",
        "aoi_1_city = []\n",
        "for i in range(len(df.lat)):\n",
        "  lats, late = df.lat[i]-0.20, df.lat[i]+0.20\n",
        "  lons, lone = df.lon[i]-0.20, df.lon[i]+0.20\n",
        "  aoi = ee.Geometry.Polygon(\n",
        "        [[[lons, lats],\n",
        "          [lone, lats],\n",
        "          [lone, late],\n",
        "          [lons, late]]])\n",
        "  aoi_1_city.append(aoi)\n",
        "aoi_1_city[2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8vOji41DvthF",
        "outputId": "60fb8642-74bb-4077-e57f-51f58e81cfdf"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ee.Geometry({\n",
              "  \"functionInvocationValue\": {\n",
              "    \"functionName\": \"GeometryConstructors.Polygon\",\n",
              "    \"arguments\": {\n",
              "      \"coordinates\": {\n",
              "        \"constantValue\": [\n",
              "          [\n",
              "            [\n",
              "              -94.3266,\n",
              "              29.880200000000002\n",
              "            ],\n",
              "            [\n",
              "              -93.9266,\n",
              "              29.880200000000002\n",
              "            ],\n",
              "            [\n",
              "              -93.9266,\n",
              "              30.2802\n",
              "            ],\n",
              "            [\n",
              "              -94.3266,\n",
              "              30.2802\n",
              "            ]\n",
              "          ]\n",
              "        ]\n",
              "      },\n",
              "      \"evenOdd\": {\n",
              "        \"constantValue\": true\n",
              "      }\n",
              "    }\n",
              "  }\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "coords = aoi_1_city[0].coordinates().getInfo()[0]\n",
        "coords"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "462UBU0dwvh8",
        "outputId": "fe0aec76-d3d4-47b1-9004-039e6781970a"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[-76.8122, 39.090399999999995],\n",
              " [-76.4122, 39.090399999999995],\n",
              " [-76.4122, 39.4904],\n",
              " [-76.8122, 39.4904],\n",
              " [-76.8122, 39.090399999999995]]"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ndui_1999_2022 for Listed Cities\n",
        "dates = pd.date_range('1999', '2022', freq='YS')\n",
        "ndui_city = []\n",
        "for i in range(2):\n",
        "    print(city_name[i])\n",
        "    ndui_c_ = []\n",
        "    for year_ in range(1999,2023):\n",
        "        print(year_)\n",
        "        year = str(year_)#'1999'\n",
        "        # ds_dmsp_interp = ds_dmsp.sel(time=slice(year, year)).interp(lon=ds_ndvi.x, lat=ds_ndvi.y).dmsp.values[0,:,:]/63.0\n",
        "        # L7 = ee.ImageCollection('LE7_L1T_TOA').filterDate(year+'-01-01', year+'-12-31')\n",
        "        if year_ == 1999:\n",
        "            L7 = ee.ImageCollection(\"LANDSAT/LE07/C02/T1_TOA\").filterDate(str(year_)+'-01-01', str(year_+2)+'-12-31')\n",
        "            print(year_)\n",
        "            print(str(year_)+'-01-01', str(year_+2)+'-12-31')\n",
        "        elif year_ == 2000:\n",
        "            L7 = ee.ImageCollection(\"LANDSAT/LE07/C02/T1_TOA\").filterDate(str(year_-1)+'-01-01', str(year_+1)+'-12-31')\n",
        "            print(year_)\n",
        "            print(str(year_-1)+'-01-01', str(year_+1)+'-12-31')\n",
        "        else:\n",
        "            L7 = ee.ImageCollection(\"LANDSAT/LE07/C02/T1_TOA\").filterDate(str(year_-2)+'-01-01', str(year_)+'-12-31')\n",
        "            print(year_)\n",
        "            print(str(year_-2)+'-01-01', str(year_)+'-12-31')\n",
        "\n",
        "        def fun4(img):\n",
        "            bad1 = img.select('B1').eq(0.0)\n",
        "            bad2 = img.select('B2').eq(0.0)\n",
        "            bad3 = img.select('B3').eq(0.0)\n",
        "            bad4 = img.select('B4').eq(0.0)\n",
        "            bad5 = img.select('B5').eq(0.0)\n",
        "            bad7 = img.select('B7').eq(0.0)\n",
        "            mask = img.mask().And(bad1.Or(bad2).Or(bad3).Or(bad4).Or(bad5).Or(bad7).Not())\n",
        "            #var mask = img.select('10','20','30','40','50','70').mask().reduce('product').eq(1);\n",
        "            masked = img.mask(mask);\n",
        "            ndvi = masked.normalizedDifference([\"B4\",\"B3\"])\n",
        "            return ndvi\n",
        "\n",
        "        NDVIs = L7.map(fun4)\n",
        "\n",
        "        Mean_NDVI = NDVIs.median()\n",
        "        Max_NDVI = NDVIs.max()\n",
        "        Min_NDVI = NDVIs.min()\n",
        "        mosaic = Mean_NDVI.where(Max_NDVI.gt(0.4), Max_NDVI)\n",
        "        mosaic = mosaic.where(Min_NDVI.lt(-0.2), Min_NDVI)\n",
        "\n",
        "        mosaic = mosaic.set('system:time_start', 0)\n",
        "        ds_ndvi_c = mosaic.wx.to_xarray(region=aoi_city[i].bounds(), scale=30)\n",
        "        ds_ndvi_c_ = ds_ndvi_c.nd.values[0,:,:]\n",
        "        ds_dmsp_interp_c = ds_dmsp_1992_2022_city[i].sel(time=slice(year, year)).interp(lon=ds_ndvi_c.x, lat=ds_ndvi_c.y).dmsp.values[0,:,:]/63.0\n",
        "        # ds_ndvi_c_ = mosaic.wx.to_xarray(region=aoi_city[i].bounds(), scale=30).nd.values[0,:,:]\n",
        "\n",
        "        ndui_c = (ds_dmsp_interp_c - ds_ndvi_c_)/(ds_dmsp_interp_c + ds_ndvi_c_)\n",
        "        ndui_c[ndui_c>1.0] = 1.0\n",
        "        ndui_c[ndui_c<-1.0] = -1.0\n",
        "        ndui_c_.append(ndui_c)\n",
        "    print(len(ndui_c_))\n",
        "    print(np.stack(ndui_c_).shape)\n",
        "\n",
        "    ndui_c_stack = np.stack(ndui_c_)\n",
        "    ds_ndui_c = xr.Dataset({\n",
        "        'ndui': xr.DataArray(\n",
        "            data   = ndui_c_stack,   # enter data here\n",
        "            dims   = ['time', 'lat', 'lon'],\n",
        "            coords = {'time':dates, 'lat': ds_ndvi_c.y.values, 'lon': ds_ndvi_c.x.values},\n",
        "            ),\n",
        "        },\n",
        "                                               )\n",
        "    print(ds_ndui_c)\n",
        "    ndui_city.append(ds_ndui_c)\n",
        "ndui_city[0]"
      ],
      "metadata": {
        "id": "7ofVCwhpwzTZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(2):\n",
        "  ndui_city[i].to_netcdf(cities_folder+city_names[i]+'/ndui_1992_2022_'+str(city_name[i])+'.nc')"
      ],
      "metadata": {
        "id": "rX9veB7ZxP5i"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}